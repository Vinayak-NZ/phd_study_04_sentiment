{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "606c39fe-9f9f-4c37-ba26-2bc37c1d3d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# reading docfiles\n",
    "import docx2txt\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.lda_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbf82c2a-8b8c-4711-bf7e-7fc3eefea6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_exclusions = pd.read_excel(\"input/word_exclusions.xlsx\")\n",
    "\n",
    "word_exclusions = word_exclusions[word_exclusions[\"exclude\"] == 1]\n",
    "\n",
    "word_exclusions = word_exclusions.drop(columns=['exclude', 'exclude_short_list'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82798596-aa7b-4c77-9eea-64981848ffea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "stop_words.extend(word_exclusions[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49830eb3-f7b1-4023-af85-b0a325020bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"input/app_v1/app_v1_feedback.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6c49cf3-2633-474e-af1e-9429eeb091a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feedback = df[df[\"category_id\"] == 9]\n",
    "\n",
    "feedback = feedback.drop(columns=['transcript_id', 'person_id', 'segment_id', 'context', 'lesson', 'category_id'], \n",
    "             axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f5d3c59-e98d-4db0-a92b-b68825024ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feedback['text_processed'] = \\\n",
    "feedback['text'].map(lambda x: re.sub('[,.!?]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9aad1885-59e5-4662-94bd-a861ffe649dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feedback['text_processed'] = \\\n",
    "feedback['text_processed'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "963e9027-4de4-451f-9861-b5878b74e22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), \n",
    "                                             deacc = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "796e8465-bfc8-4d66-b608-1d25eca6541b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = feedback.text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af2f5684-5fb2-4bb7-a6a2-632baca6d93a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inhaltlich Natur schon Studium bekannt finden gut jetzt noch einmal wiederholen auffrischen', 'machen immer noch einmal wieder so bewussen Lage versetzen klar deutlich kommunizieren auch noch einmal nachfragen richtig verstehen glauben gerade Vorbereitung Geburt jetzt noch einmal ganz gut auffrischen']\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load(\"de_core_news_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d8e49ad0-bdbb-41f1-94cf-c284bbe474fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanandkuma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ber', 'berhaupt', 'chlich', 'daf', 'hrend', 'nnen', 'nnte', 'rde', 'rden', 'rdest', 'ren', 'tats', 'tte'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=5,                        # minimum reqd occurences of a word \n",
    "                             stop_words=stop_words,             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2bd6cab0-6626-442b-8f89-b3f6b0c7d832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  22.340425531914892 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8d7b2a2-3a29-484e-96f9-72b63949da4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(n_components=2, random_state=100)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Build LDA Model\n",
    "    lda_model = LatentDirichletAllocation(n_components=2,               # Number of topics\n",
    "                                          max_iter=10,               # Max learning iterations\n",
    "                                          learning_method='batch',   \n",
    "                                          random_state=100,          # Random state\n",
    "                                          evaluate_every = -1       # compute perplexity every n iters, default: Don't\n",
    "                                         )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ea8d6d2-bf76-49ed-9b79-999c3fa9bb78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -127.18212049276376\n",
      "Perplexity:  5.997228655232542\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'batch',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 2,\n",
      " 'n_jobs': None,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b34925a1-0275-4b88-99a0-5a653183f2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [2, 5, 10]})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [2, 5, 10], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "13557d06-4816-4c2e-bd09-45eb9cf4113e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 2}\n",
      "Best Log Likelihood Score:  -35.220153201401665\n",
      "Model Perplexity:  5.997071939585868\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5045f3dd-9dbd-4123-af69-ed5b1d2f3955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fe0cc_row0_col0, #T_fe0cc_row0_col1, #T_fe0cc_row1_col0, #T_fe0cc_row1_col1, #T_fe0cc_row2_col0, #T_fe0cc_row2_col1, #T_fe0cc_row2_col2, #T_fe0cc_row3_col0, #T_fe0cc_row3_col1, #T_fe0cc_row4_col0, #T_fe0cc_row4_col1, #T_fe0cc_row5_col0, #T_fe0cc_row5_col1, #T_fe0cc_row6_col0, #T_fe0cc_row6_col1, #T_fe0cc_row7_col0, #T_fe0cc_row7_col1, #T_fe0cc_row8_col0, #T_fe0cc_row9_col0, #T_fe0cc_row9_col1, #T_fe0cc_row10_col0, #T_fe0cc_row10_col1, #T_fe0cc_row11_col0, #T_fe0cc_row11_col1, #T_fe0cc_row11_col2, #T_fe0cc_row12_col0, #T_fe0cc_row12_col1, #T_fe0cc_row13_col0, #T_fe0cc_row13_col1, #T_fe0cc_row14_col0, #T_fe0cc_row14_col1 {\n",
       "  color: green;\n",
       "  font-weight: 700;\n",
       "}\n",
       "#T_fe0cc_row0_col2, #T_fe0cc_row1_col2, #T_fe0cc_row3_col2, #T_fe0cc_row4_col2, #T_fe0cc_row5_col2, #T_fe0cc_row6_col2, #T_fe0cc_row7_col2, #T_fe0cc_row8_col1, #T_fe0cc_row8_col2, #T_fe0cc_row9_col2, #T_fe0cc_row10_col2, #T_fe0cc_row12_col2, #T_fe0cc_row13_col2, #T_fe0cc_row14_col2 {\n",
       "  color: black;\n",
       "  font-weight: 400;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fe0cc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fe0cc_level0_col0\" class=\"col_heading level0 col0\" >Topic0</th>\n",
       "      <th id=\"T_fe0cc_level0_col1\" class=\"col_heading level0 col1\" >Topic1</th>\n",
       "      <th id=\"T_fe0cc_level0_col2\" class=\"col_heading level0 col2\" >dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "      <td id=\"T_fe0cc_row0_col0\" class=\"data row0 col0\" >0.830000</td>\n",
       "      <td id=\"T_fe0cc_row0_col1\" class=\"data row0 col1\" >0.170000</td>\n",
       "      <td id=\"T_fe0cc_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "      <td id=\"T_fe0cc_row1_col0\" class=\"data row1 col0\" >0.830000</td>\n",
       "      <td id=\"T_fe0cc_row1_col1\" class=\"data row1 col1\" >0.170000</td>\n",
       "      <td id=\"T_fe0cc_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "      <td id=\"T_fe0cc_row2_col0\" class=\"data row2 col0\" >0.290000</td>\n",
       "      <td id=\"T_fe0cc_row2_col1\" class=\"data row2 col1\" >0.710000</td>\n",
       "      <td id=\"T_fe0cc_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "      <td id=\"T_fe0cc_row3_col0\" class=\"data row3 col0\" >0.830000</td>\n",
       "      <td id=\"T_fe0cc_row3_col1\" class=\"data row3 col1\" >0.170000</td>\n",
       "      <td id=\"T_fe0cc_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "      <td id=\"T_fe0cc_row4_col0\" class=\"data row4 col0\" >0.830000</td>\n",
       "      <td id=\"T_fe0cc_row4_col1\" class=\"data row4 col1\" >0.170000</td>\n",
       "      <td id=\"T_fe0cc_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "      <td id=\"T_fe0cc_row5_col0\" class=\"data row5 col0\" >0.870000</td>\n",
       "      <td id=\"T_fe0cc_row5_col1\" class=\"data row5 col1\" >0.130000</td>\n",
       "      <td id=\"T_fe0cc_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "      <td id=\"T_fe0cc_row6_col0\" class=\"data row6 col0\" >0.810000</td>\n",
       "      <td id=\"T_fe0cc_row6_col1\" class=\"data row6 col1\" >0.190000</td>\n",
       "      <td id=\"T_fe0cc_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "      <td id=\"T_fe0cc_row7_col0\" class=\"data row7 col0\" >0.870000</td>\n",
       "      <td id=\"T_fe0cc_row7_col1\" class=\"data row7 col1\" >0.130000</td>\n",
       "      <td id=\"T_fe0cc_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "      <td id=\"T_fe0cc_row8_col0\" class=\"data row8 col0\" >0.900000</td>\n",
       "      <td id=\"T_fe0cc_row8_col1\" class=\"data row8 col1\" >0.100000</td>\n",
       "      <td id=\"T_fe0cc_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "      <td id=\"T_fe0cc_row9_col0\" class=\"data row9 col0\" >0.760000</td>\n",
       "      <td id=\"T_fe0cc_row9_col1\" class=\"data row9 col1\" >0.240000</td>\n",
       "      <td id=\"T_fe0cc_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "      <td id=\"T_fe0cc_row10_col0\" class=\"data row10 col0\" >0.870000</td>\n",
       "      <td id=\"T_fe0cc_row10_col1\" class=\"data row10 col1\" >0.130000</td>\n",
       "      <td id=\"T_fe0cc_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "      <td id=\"T_fe0cc_row11_col0\" class=\"data row11 col0\" >0.130000</td>\n",
       "      <td id=\"T_fe0cc_row11_col1\" class=\"data row11 col1\" >0.870000</td>\n",
       "      <td id=\"T_fe0cc_row11_col2\" class=\"data row11 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "      <td id=\"T_fe0cc_row12_col0\" class=\"data row12 col0\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row12_col1\" class=\"data row12 col1\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "      <td id=\"T_fe0cc_row13_col0\" class=\"data row13 col0\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row13_col1\" class=\"data row13 col1\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fe0cc_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "      <td id=\"T_fe0cc_row14_col0\" class=\"data row14 col0\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row14_col1\" class=\"data row14 col1\" >0.500000</td>\n",
       "      <td id=\"T_fe0cc_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ae2a3d960>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64f2cf5e-3ee2-4176-9cac-7ddda75dfc1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Num</th>\n",
       "      <th>Num Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Num  Num Documents\n",
       "0          0             29\n",
       "1          1             18"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5bee4347-085f-482d-8d95-329c2c397270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanandkuma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  return fun(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finden</th>\n",
       "      <th>gen</th>\n",
       "      <th>gut</th>\n",
       "      <th>immer</th>\n",
       "      <th>lernen</th>\n",
       "      <th>personlich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>19.472843</td>\n",
       "      <td>0.508859</td>\n",
       "      <td>22.47431</td>\n",
       "      <td>5.482155</td>\n",
       "      <td>0.558103</td>\n",
       "      <td>3.133049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.527157</td>\n",
       "      <td>12.491141</td>\n",
       "      <td>0.52569</td>\n",
       "      <td>0.517845</td>\n",
       "      <td>7.441897</td>\n",
       "      <td>3.866951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           finden        gen       gut     immer    lernen  personlich\n",
       "Topic0  19.472843   0.508859  22.47431  5.482155  0.558103    3.133049\n",
       "Topic1   0.527157  12.491141   0.52569  0.517845  7.441897    3.866951"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# View\n",
    "df_topic_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85a1f846-4792-442b-b9b8-bd2b5815cc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanandkuma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  return fun(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>gen</td>\n",
       "      <td>lernen</td>\n",
       "      <td>personlich</td>\n",
       "      <td>finden</td>\n",
       "      <td>gut</td>\n",
       "      <td>immer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>gut</td>\n",
       "      <td>finden</td>\n",
       "      <td>immer</td>\n",
       "      <td>personlich</td>\n",
       "      <td>lernen</td>\n",
       "      <td>gen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 0  Word 1      Word 2      Word 3  Word 4 Word 5\n",
       "Topic 0    gen  lernen  personlich      finden     gut  immer\n",
       "Topic 1    gut  finden       immer  personlich  lernen    gen"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=50)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "13ecc6f4-d873-449a-83df-1b002f0d151c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el12251223831116448642467529565\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el12251223831116448642467529565_data = {\"mdsDat\": {\"x\": [0.23555924655214708, -0.23555924655214708], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [66.28914455796303, 33.710855442036966]}, \"tinfo\": {\"Term\": [\"gen\", \"lernen\", \"gut\", \"finden\", \"personlich\", \"immer\", \"gut\", \"finden\", \"immer\", \"personlich\", \"lernen\", \"gen\", \"gen\", \"lernen\", \"personlich\", \"immer\", \"finden\", \"gut\"], \"Freq\": [12.0, 7.0, 20.0, 18.0, 6.0, 5.0, 20.493447531474683, 17.75652188356484, 4.998972683775407, 2.8432624102724025, 0.5090664975796324, 0.4640216294868031, 11.777243456786794, 7.016424336289402, 3.660060155946147, 0.4882468304667653, 0.4970585134033988, 0.4956740709537414], \"Total\": [12.0, 7.0, 20.0, 18.0, 6.0, 5.0, 20.989121602428423, 18.25358039696824, 5.487219514242172, 6.50332256621855, 7.525490833869035, 12.241265086273597, 12.241265086273597, 7.525490833869035, 6.50332256621855, 5.487219514242172, 18.25358039696824, 20.989121602428423], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.8314, -0.9748, -2.2423, -2.8066, -4.5267, -4.6194, -0.7092, -1.2271, -1.8779, -3.8923, -3.8744, -3.8772], \"loglift\": [6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3872, 0.3835, 0.318, -0.4162, -2.2823, -2.8615, 1.0487, 1.0173, 0.5125, -1.332, -2.5161, -2.6585]}, \"token.table\": {\"Topic\": [1, 2, 1, 1, 1, 2, 1, 2], \"Freq\": [0.9861079091633794, 0.9802908372154989, 0.9528745594425456, 0.9112083063238885, 0.1328816979617363, 0.930171885732154, 0.46130266020994753, 0.6150702136132634], \"Term\": [\"finden\", \"gen\", \"gut\", \"immer\", \"lernen\", \"lernen\", \"personlich\", \"personlich\"]}, \"R\": 6, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el12251223831116448642467529565\", ldavis_el12251223831116448642467529565_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el12251223831116448642467529565\", ldavis_el12251223831116448642467529565_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el12251223831116448642467529565\", ldavis_el12251223831116448642467529565_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "1      0.235559  0.0       1        1  66.289145\n",
       "0     -0.235559  0.0       2        1  33.710855, topic_info=         Term       Freq      Total Category  logprob  loglift\n",
       "1         gen  12.000000  12.000000  Default   6.0000   6.0000\n",
       "4      lernen   7.000000   7.000000  Default   5.0000   5.0000\n",
       "2         gut  20.000000  20.000000  Default   4.0000   4.0000\n",
       "0      finden  18.000000  18.000000  Default   3.0000   3.0000\n",
       "5  personlich   6.000000   6.000000  Default   2.0000   2.0000\n",
       "3       immer   5.000000   5.000000  Default   1.0000   1.0000\n",
       "2         gut  20.493448  20.989122   Topic1  -0.8314   0.3872\n",
       "0      finden  17.756522  18.253580   Topic1  -0.9748   0.3835\n",
       "3       immer   4.998973   5.487220   Topic1  -2.2423   0.3180\n",
       "5  personlich   2.843262   6.503323   Topic1  -2.8066  -0.4162\n",
       "4      lernen   0.509066   7.525491   Topic1  -4.5267  -2.2823\n",
       "1         gen   0.464022  12.241265   Topic1  -4.6194  -2.8615\n",
       "1         gen  11.777243  12.241265   Topic2  -0.7092   1.0487\n",
       "4      lernen   7.016424   7.525491   Topic2  -1.2271   1.0173\n",
       "5  personlich   3.660060   6.503323   Topic2  -1.8779   0.5125\n",
       "3       immer   0.488247   5.487220   Topic2  -3.8923  -1.3320\n",
       "0      finden   0.497059  18.253580   Topic2  -3.8744  -2.5161\n",
       "2         gut   0.495674  20.989122   Topic2  -3.8772  -2.6585, token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "0         1  0.986108      finden\n",
       "1         2  0.980291         gen\n",
       "2         1  0.952875         gut\n",
       "3         1  0.911208       immer\n",
       "4         1  0.132882      lernen\n",
       "4         2  0.930172      lernen\n",
       "5         1  0.461303  personlich\n",
       "5         2  0.615070  personlich, R=6, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.lda_model.prepare(best_lda_model, data_vectorized, vectorizer)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdaea51-3658-458c-af36-fc63bbc43e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25308b84-64a5-4ba4-b2fc-4c5f7a9452ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'num_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTopic_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i): [token \u001b[38;5;28;01mfor\u001b[39;00m token, score \u001b[38;5;129;01min\u001b[39;00m best_lda_model\u001b[38;5;241m.\u001b[39mshow_topic(i, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43mbest_lda_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_components\u001b[49m)}\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_dict)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'num_components'"
     ]
    }
   ],
   "source": [
    "my_dict = {'Topic_' + str(i): [token for token, score in best_lda_model.show_topic(i, topn=10)] for i in range(0, best_lda_model.num_topics)}\n",
    "\n",
    "print(my_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
